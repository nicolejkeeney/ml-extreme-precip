{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e908184f-6668-4f2f-a3e2-9f055c746c55",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c748385-fb07-4a9e-b20d-a08c4d1deeaa",
   "metadata": {},
   "source": [
    "## 0. Setup \n",
    "Import packages. Set random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da1acfdf-b405-4677-ab47-da94f77f5526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T17:28:47.227658Z",
     "iopub.status.busy": "2023-10-13T17:28:47.226317Z",
     "iopub.status.idle": "2023-10-13T17:28:50.868500Z",
     "shell.execute_reply": "2023-10-13T17:28:50.867917Z",
     "shell.execute_reply.started": "2023-10-13T17:28:47.227499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-13 17:28:48.393099: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import keras_tuner as kt \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras import metrics \n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# Import helper functions \n",
    "import sys\n",
    "sys.path.insert(0, '../../utils')\n",
    "from cnn_utils import onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52fe4aad-6652-4310-90f8-6d1c347b4678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T17:28:50.870512Z",
     "iopub.status.busy": "2023-10-13T17:28:50.869764Z",
     "iopub.status.idle": "2023-10-13T17:28:50.875669Z",
     "shell.execute_reply": "2023-10-13T17:28:50.874436Z",
     "shell.execute_reply.started": "2023-10-13T17:28:50.870489Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set random seeds \n",
    "np.random.seed(220)\n",
    "tf.random.set_seed(117)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a5602-e8de-4ff9-93a8-d8171db34b1c",
   "metadata": {},
   "source": [
    "## 1. Read and preprocess input data\n",
    "Read in the data, convert it to numpy arrays, perform one hot encoding, and compute class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa485479-ac30-4704-bc93-fcd410aa2465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T17:28:50.878312Z",
     "iopub.status.busy": "2023-10-13T17:28:50.877382Z",
     "iopub.status.idle": "2023-10-13T17:28:50.901266Z",
     "shell.execute_reply": "2023-10-13T17:28:50.900101Z",
     "shell.execute_reply.started": "2023-10-13T17:28:50.878281Z"
    }
   },
   "outputs": [],
   "source": [
    "# Class 0: no extreme precip \n",
    "# Class 1: extreme precip\n",
    "classes = [0,1]\n",
    "\n",
    "# Columns to use for labels vs. features \n",
    "labels = \"precip_classes\"\n",
    "features_list = [\"slp_anom\",\"hgt_detrended_anom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47b77c92-c98d-4113-acf6-fbde5ed86193",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T17:28:50.903734Z",
     "iopub.status.busy": "2023-10-13T17:28:50.902550Z",
     "iopub.status.idle": "2023-10-13T17:28:51.207619Z",
     "shell.execute_reply": "2023-10-13T17:28:51.206686Z",
     "shell.execute_reply.started": "2023-10-13T17:28:50.903659Z"
    }
   },
   "outputs": [],
   "source": [
    "# Directory for input data \n",
    "data_dir = \"../../data/input_data_preprocessed/\"\n",
    "\n",
    "# Read csv as pandas DataFrame object\n",
    "x_train_ds = xr.open_dataset(data_dir+\"training/training_features.nc\")\n",
    "y_train_df = pd.read_csv(data_dir+\"training/training_labels.csv\", index_col=False)\n",
    "\n",
    "x_val_ds = xr.open_dataset(data_dir+\"validation/validation_features.nc\")\n",
    "y_val_df = pd.read_csv(data_dir+\"validation/validation_labels.csv\", index_col=False)\n",
    "\n",
    "x_test_ds = xr.open_dataset(data_dir+\"testing/testing_features.nc\")\n",
    "y_test_df = pd.read_csv(data_dir+\"testing/testing_labels.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb1579-8503-4e04-98ae-b59b9315b42c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T17:53:55.052759Z",
     "iopub.status.busy": "2023-10-11T17:53:55.052239Z",
     "iopub.status.idle": "2023-10-11T17:53:55.078792Z",
     "shell.execute_reply": "2023-10-11T17:53:55.073521Z",
     "shell.execute_reply.started": "2023-10-11T17:53:55.052717Z"
    }
   },
   "source": [
    "### 1.1 Convert to data numpy arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92ea1738-f8bc-45d6-9f4a-b6af5f5b72b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T17:28:51.209355Z",
     "iopub.status.busy": "2023-10-13T17:28:51.209020Z",
     "iopub.status.idle": "2023-10-13T17:28:51.870447Z",
     "shell.execute_reply": "2023-10-13T17:28:51.868872Z",
     "shell.execute_reply.started": "2023-10-13T17:28:51.209328Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = x_train_ds.to_array().transpose(\"time\",\"lat\",\"lon\",\"variable\").values\n",
    "y_train = y_train_df[labels].values\n",
    "\n",
    "x_val = x_val_ds.to_array().transpose(\"time\",\"lat\",\"lon\",\"variable\").values\n",
    "y_val = y_val_df[labels].values\n",
    "\n",
    "x_test = x_test_ds.to_array().transpose(\"time\",\"lat\",\"lon\",\"variable\").values\n",
    "y_test = y_test_df[labels].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd97f77b-e2df-4cf5-b16e-75b8835e4526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T17:54:22.029950Z",
     "iopub.status.busy": "2023-10-11T17:54:22.029135Z",
     "iopub.status.idle": "2023-10-11T17:54:22.071709Z",
     "shell.execute_reply": "2023-10-11T17:54:22.064649Z",
     "shell.execute_reply.started": "2023-10-11T17:54:22.029884Z"
    }
   },
   "source": [
    "### 1.2 Compute class weights\n",
    "Class weights should be inversely proportional to frequency of each class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e7827f4-7dc8-4300-9b0d-10f3dd9f7c8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T17:28:51.874510Z",
     "iopub.status.busy": "2023-10-13T17:28:51.872793Z",
     "iopub.status.idle": "2023-10-13T17:28:51.892308Z",
     "shell.execute_reply": "2023-10-13T17:28:51.887430Z",
     "shell.execute_reply.started": "2023-10-13T17:28:51.874326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.5271939953810624, 1: 9.6932059447983}\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", \n",
    "    classes=np.array(classes), \n",
    "    y=y_train\n",
    ")\n",
    "class_weights = {classes[0]:class_weights[0], classes[1]:class_weights[1]}\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe01776-3863-40b1-88ed-738b975b3cfb",
   "metadata": {},
   "source": [
    "### 1.2 Do one hot encoding on labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "470d9dd8-7927-4801-bf94-9a572e5c7caa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T17:28:51.905838Z",
     "iopub.status.busy": "2023-10-13T17:28:51.904946Z",
     "iopub.status.idle": "2023-10-13T17:28:51.932537Z",
     "shell.execute_reply": "2023-10-13T17:28:51.926869Z",
     "shell.execute_reply.started": "2023-10-13T17:28:51.905776Z"
    }
   },
   "outputs": [],
   "source": [
    "## Print docstrings for one hot encoding function\n",
    "# print(onehot.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "168881aa-5331-4882-a966-21ebcefba2af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T17:28:51.938899Z",
     "iopub.status.busy": "2023-10-13T17:28:51.937749Z",
     "iopub.status.idle": "2023-10-13T17:28:51.973692Z",
     "shell.execute_reply": "2023-10-13T17:28:51.970549Z",
     "shell.execute_reply.started": "2023-10-13T17:28:51.938824Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_onehot = onehot(y_train)\n",
    "y_val_onehot = onehot(y_val)\n",
    "y_test_onehot = onehot(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec3a4bd-8c6b-401e-86c7-b1b3048b459e",
   "metadata": {},
   "source": [
    "## 2. Build and train the CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2357f4ef-e007-492b-973c-21ce443db8c8",
   "metadata": {},
   "source": [
    "### 2.1 Define model hyperparameters/settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c20a2f-d621-4ec0-a42a-ccd94b79dff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T17:28:51.978373Z",
     "iopub.status.busy": "2023-10-13T17:28:51.977078Z",
     "iopub.status.idle": "2023-10-13T17:28:52.001643Z",
     "shell.execute_reply": "2023-10-13T17:28:52.000042Z",
     "shell.execute_reply.started": "2023-10-13T17:28:51.978320Z"
    }
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "settings = {\n",
    "    \"batch_size\": 2048, \n",
    "    \"epochs\": 500,\n",
    "    \"callbacks\": [callback],\n",
    "    \"cell_output\": 0, # 0: Silent during model.fit; 1: Progress bar; 2: Prints each epoch\n",
    "    \"class_weights\": class_weights\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a9237c-a88e-4709-a464-f860362911fc",
   "metadata": {},
   "source": [
    "### 2.2 Build the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "205a6abd-0af6-4749-8391-7d9cdf881756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T17:28:52.004428Z",
     "iopub.status.busy": "2023-10-13T17:28:52.003571Z",
     "iopub.status.idle": "2023-10-13T17:28:52.049376Z",
     "shell.execute_reply": "2023-10-13T17:28:52.047191Z",
     "shell.execute_reply.started": "2023-10-13T17:28:52.004381Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_uncompiled_model(data_shape=(15, 35, 2), conv_filters=16, dense_neurons=16, dense_layers=1, activity_reg=0.001, dropout_rate=0.2): \n",
    "    \"\"\"Build uncompiled CNN \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_shape: tuple \n",
    "        Shape of data in the form (lat, lon, num_classes) \n",
    "    conv_filters: int \n",
    "        Number of filters to use in convolution layer \n",
    "    dense_neurons: int \n",
    "        Number of dense neurons to use in dense layer\n",
    "    dense_layers: int \n",
    "        Number of dense layers to use \n",
    "    activity_reg: float \n",
    "        Regularization factor for l2 regularization \n",
    "    dropout_rate: float \n",
    "        Dropout rate\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    keras.engine.sequential.Sequential\n",
    "        Uncompiled model \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    model = models.Sequential() \n",
    "    model.add(layers.Input(shape=data_shape)) ## define input shape\n",
    "\n",
    "    # Convolutional and pooling layers are the feature extraction portion of the network\n",
    "    model.add(layers.Conv2D(conv_filters, \n",
    "                            (3,3), activity_regularizer=regularizers.l2(0.01))) \n",
    "    model.add(layers.Activation('relu')) ## add convolutional layer\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "                            \n",
    "    model.add(layers.Conv2D(conv_filters, (3,3), activity_regularizer=regularizers.l2(activity_reg))) \n",
    "    model.add(layers.Activation('relu')) ## add convolutional layer\n",
    "    model.add(layers.MaxPooling2D((2,2))) ## pooling layer\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "                            \n",
    "    model.add(layers.Flatten()) ## converts from 2D array to 1D array\n",
    "\n",
    "    # Feature interpretation layers \n",
    "    for i in range(dense_layers):\n",
    "        model.add(layers.Dense(dense_neurons, activity_regularizer=regularizers.l2(activity_reg))) ## dense layer\n",
    "        model.add(layers.Activation('relu'))\n",
    "     \n",
    "    model.add(layers.Dense(2, activation='softmax')) ## classifier layer (binary class where 1=extreme)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43c4d920-28b5-4402-a712-f580c313bf89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T17:28:52.054539Z",
     "iopub.status.busy": "2023-10-13T17:28:52.052197Z",
     "iopub.status.idle": "2023-10-13T17:28:52.073451Z",
     "shell.execute_reply": "2023-10-13T17:28:52.070409Z",
     "shell.execute_reply.started": "2023-10-13T17:28:52.054503Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_compiled_model(data_shape=(15, 35, 2), lr=0.0004, **kwargs): \n",
    "    \"\"\"Get incompiled model, and then.... compile it \n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    lr: float \n",
    "        Learning rate \n",
    "\n",
    "    Returns \n",
    "    --------\n",
    "    keras.engine.sequential.Sequential\n",
    "        Compiled model \n",
    "    \"\"\"\n",
    "    # Get uncompiled model \n",
    "    model = get_uncompiled_model(data_shape=data_shape, **kwargs) \n",
    "\n",
    "    # Set metrics \n",
    "    # https://stackoverflow.com/questions/58630393/does-tf-keras-metrics-auc-work-on-multi-class-problems\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC\n",
    "    METRICS = [\n",
    "        metrics.CategoricalAccuracy(name='accuracy'),\n",
    "        metrics.Precision(class_id=1, name='precision'),\n",
    "        metrics.Recall(class_id=1, name='recall'),\n",
    "        tf.keras.metrics.AUC(curve=\"ROC\", multi_label=False)\n",
    "    ]\n",
    "\n",
    "    # Compile model \n",
    "    model.compile(loss=losses.CategoricalCrossentropy(), \n",
    "                  optimizer=optimizers.Adam(learning_rate=lr), \n",
    "                  metrics=METRICS)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c8d6cd4-75be-44cc-9959-b837d16b245f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T17:28:52.076209Z",
     "iopub.status.busy": "2023-10-13T17:28:52.075746Z",
     "iopub.status.idle": "2023-10-13T17:28:52.433276Z",
     "shell.execute_reply": "2023-10-13T17:28:52.432347Z",
     "shell.execute_reply.started": "2023-10-13T17:28:52.076185Z"
    }
   },
   "outputs": [],
   "source": [
    "data_shape = (x_train_ds.dims[\"lat\"], x_train_ds.dims[\"lon\"], 2) # lat, lon, num classes \n",
    "model = get_compiled_model(data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f6ed394-4f5d-41aa-88a0-a12031d89633",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T17:28:52.434869Z",
     "iopub.status.busy": "2023-10-13T17:28:52.434604Z",
     "iopub.status.idle": "2023-10-13T17:28:52.441547Z",
     "shell.execute_reply": "2023-10-13T17:28:52.438926Z",
     "shell.execute_reply.started": "2023-10-13T17:28:52.434849Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add initial weights at some point to preserve reproducability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2a0523d-2e0c-41f3-b914-ed70b9c31814",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T17:28:52.443845Z",
     "iopub.status.busy": "2023-10-13T17:28:52.443115Z",
     "iopub.status.idle": "2023-10-13T17:28:52.501380Z",
     "shell.execute_reply": "2023-10-13T17:28:52.499890Z",
     "shell.execute_reply.started": "2023-10-13T17:28:52.443801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 13, 33, 16)        304       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 13, 33, 16)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 6, 16, 16)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6, 16, 16)         0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 4, 14, 16)         2320      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 4, 14, 16)         0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 2, 7, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2, 7, 16)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 224)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                3600      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,258\n",
      "Trainable params: 6,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344509f2-fbcb-40f7-889e-b42777d7ba92",
   "metadata": {},
   "source": [
    "### 2.3 Tune the model parameters \n",
    "Reference page: https://keras.io/guides/keras_tuner/getting_started/\n",
    "\n",
    "Note to self: KT objective should be the same as the LOSS. Need to pick one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f826c0b8-3b49-4fd6-acbf-d7c394bebdd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T17:28:52.508275Z",
     "iopub.status.busy": "2023-10-13T17:28:52.507078Z",
     "iopub.status.idle": "2023-10-13T17:28:52.548797Z",
     "shell.execute_reply": "2023-10-13T17:28:52.544074Z",
     "shell.execute_reply.started": "2023-10-13T17:28:52.508065Z"
    }
   },
   "outputs": [],
   "source": [
    "# def build_model_hp(hp): \n",
    "#     \"\"\"Build and compile CNN \n",
    "    \n",
    "#     Parameters \n",
    "#     ----------\n",
    "#     None\n",
    "    \n",
    "#     Returns \n",
    "#     --------\n",
    "#     keras.engine.sequential.Sequential\n",
    "#         Compiled model \n",
    "#     \"\"\"\n",
    "#     # Define hyperparameters to optimize \n",
    "#     learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "\n",
    "#     # Build model\n",
    "#     model = models.Sequential() \n",
    "#     model.add(layers.Input(shape=(15, 35, 2))) ## define input shape\n",
    "\n",
    "#     # Convolutional layers\n",
    "#     model.add(layers.Conv2D(16, (3,3), activity_regularizer=regularizers.l2(0.01))) \n",
    "#     model.add(layers.Activation('relu')) ## add convolutional layer\n",
    "#     model.add(layers.MaxPooling2D((2,2)))\n",
    "#     model.add(layers.Dropout(0.2))                  \n",
    "#     model.add(layers.Conv2D(16, (3,3), activity_regularizer=regularizers.l2(0.001))) \n",
    "#     model.add(layers.Activation('relu')) ## add convolutional layer\n",
    "#     model.add(layers.MaxPooling2D((2,2))) ## pooling layer\n",
    "#     model.add(layers.Dropout(0.2))        \n",
    "\n",
    "#     # Dense layer\n",
    "#     model.add(layers.Flatten()) ## converts from 2D array to 1D array\n",
    "#     model.add(layers.Dense(16, activity_regularizer=regularizers.l2(0.001))) ## dense layer\n",
    "#     model.add(layers.Activation('relu'))\n",
    "#     model.add(layers.Dense(2, activation='softmax')) ## classifier layer (binary class where 1=extreme)\n",
    "\n",
    "#     # Compile model \n",
    "#     METRICS = [\n",
    "#         metrics.CategoricalAccuracy(name='accuracy'),\n",
    "#         metrics.Precision(class_id=1, name='precision'),\n",
    "#         metrics.Recall(class_id=1, name='recall'),\n",
    "#         tf.keras.metrics.AUC(curve=\"ROC\", multi_label=False)\n",
    "#     ]\n",
    "#     model.compile(loss=losses.CategoricalCrossentropy(), \n",
    "#                   optimizer=optimizers.Adam(learning_rate=learning_rate), \n",
    "#                   metrics=METRICS)\n",
    "#     return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3409fbf3-5459-45cd-8468-40a0a73c7451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T17:30:19.436349Z",
     "iopub.status.busy": "2023-10-13T17:30:19.434548Z",
     "iopub.status.idle": "2023-10-13T17:30:19.460001Z",
     "shell.execute_reply": "2023-10-13T17:30:19.458174Z",
     "shell.execute_reply.started": "2023-10-13T17:30:19.436305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_tuner.src.engine.objective.Objective at 0x7f619f7efa60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kt.Objective(\"val_categorical_crossentropy\", direction=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dcc766b-90c9-45f0-bb55-3f67b35ab698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-14T00:19:29.733598Z",
     "iopub.status.busy": "2023-10-14T00:19:29.729985Z",
     "iopub.status.idle": "2023-10-14T00:19:29.899522Z",
     "shell.execute_reply": "2023-10-14T00:19:29.898516Z",
     "shell.execute_reply.started": "2023-10-14T00:19:29.733548Z"
    }
   },
   "outputs": [],
   "source": [
    "# tuner = kt.RandomSearch(\n",
    "#     build_model_hp,\n",
    "#     objective=kt.Objective(\"val_categorical_crossentropy\", direction=\"min\"),\n",
    "#     max_trials=3,\n",
    "#     overwrite=True\n",
    "# )\n",
    "# tuner.search_space_summary()\n",
    "# tuner.search(x_train, y_train_onehot, epochs=5, validation_data=(x_val, y_val_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af3161-430e-4e65-b133-309210f938f0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-13T17:27:17.362186Z",
     "iopub.status.idle": "2023-10-13T17:27:17.363775Z",
     "shell.execute_reply": "2023-10-13T17:27:17.363541Z",
     "shell.execute_reply.started": "2023-10-13T17:27:17.363520Z"
    }
   },
   "outputs": [],
   "source": [
    "# tuner.results_summary(num_trials=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f934254-fe94-49b4-ad81-1561b3d01e3e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-13T17:27:17.364812Z",
     "iopub.status.idle": "2023-10-13T17:27:17.365183Z",
     "shell.execute_reply": "2023-10-13T17:27:17.365071Z",
     "shell.execute_reply.started": "2023-10-13T17:27:17.365058Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Get the top 2 models.\n",
    "# models = tuner.get_best_models(num_models=2)\n",
    "# best_model = models[0]\n",
    "\n",
    "# # Build the model.\n",
    "# # Needed for `Sequential` without specified `input_shape`.\n",
    "# best_model.build(input_shape=data_shape)\n",
    "# best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b23907-0284-4e1f-99fe-0f4dd9fd5e39",
   "metadata": {},
   "source": [
    "### 2.4 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f990be-99c4-4f31-b32d-df5eaed41172",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train_onehot, \n",
    "    batch_size=settings[\"batch_size\"], \n",
    "    epochs=settings[\"epochs\"], \n",
    "    class_weight=settings[\"class_weights\"], \n",
    "    validation_data=(x_val, y_val_onehot),          \n",
    "    callbacks=settings[\"callbacks\"], \n",
    "    verbose=settings[\"cell_output\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ee5ec0-56be-4e9c-a300-a30722cbb768",
   "metadata": {},
   "source": [
    "### 2.5 Plot the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ccb7b4-8052-43aa-804b-7597ba53651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history) \n",
    "hist_df[\"epoch\"] = hist_df.index\n",
    "\n",
    "print(\"Num epochs: {0}\".format(len(hist_df)))\n",
    "hist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5991d9ed-1e2a-42c8-9a7e-2d22e0419e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"loss\",\"accuracy\", \"precision\", \"recall\", \"auc\"]\n",
    "fig = plt.figure(figsize=(7, 6))\n",
    "\n",
    "for i in range(len(metrics)): \n",
    "    metric = metrics[i]\n",
    "    ax = fig.add_subplot(3,2,i+1)\n",
    "    tr_pl = hist_df.plot(\"epoch\", metric, label=\"training\", ax=ax, color=\"blue\")\n",
    "    val_pl = hist_df.plot(\"epoch\",\"val_\"+metric, label=\"validation\", ax=ax, color=\"red\")\n",
    "    ax.set_title(metric)\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "handles,labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center right', bbox_to_anchor=(0.5, 0., 0.5, 0.5))\n",
    "fig.tight_layout()\n",
    "fig.suptitle(\"Convolutional Neural Network Training and Validation Results\", y=1.04)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2453f06d-154d-48c6-b4ef-149d138952b3",
   "metadata": {},
   "source": [
    "## 3. Compute model evaluation metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c1ed3-fa55-4bf7-aa0e-601b2c4bbf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/guide/keras/training_with_built_in_methods\n",
    "loss_train, acc_train, prec_train, recall_train, auc_train = model.evaluate(\n",
    "    x_train, y_train_onehot, \n",
    "    verbose=0, \n",
    "    #batch_size=settings[\"batch_size\"]\n",
    ")\n",
    "\n",
    "loss_val, acc_val, prec_val, recall_val, auc_val = model.evaluate(\n",
    "    x_val, y_val_onehot, \n",
    "    verbose=0\n",
    "    #batch_size=settings[\"batch_size\"]\n",
    ")\n",
    "\n",
    "# loss_test, acc_test, prec_test, recall_test, auc_test = model.evaluate(\n",
    "#     x_test, y_test_onehot, \n",
    "#     #batch_size=settings[\"batch_size\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08c044-f5e7-4671-9e96-bf128561716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = pd.DataFrame(\n",
    "    {\n",
    "        \"Loss\":[loss_train,loss_val],\n",
    "        \"Accuracy\":[acc_train,acc_val],\n",
    "        \"Precision\":[prec_train,prec_val],\n",
    "        \"Recall\":[recall_train,recall_val],\n",
    "        \"AUC\":[auc_train,auc_val]\n",
    "},\n",
    "    index=[\"training\",\"validation\"]\n",
    ")\n",
    "display(model_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0877653f-d52d-429f-9713-d7bfe11fb8d6",
   "metadata": {},
   "source": [
    "## 4. Make predictions using trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4972d75b-5db4-4de4-bf43-dbd76f5a1d8f",
   "metadata": {},
   "source": [
    "Predictions are the probability that the data falls into each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42be50e2-2f80-4d3e-95af-d4a2b3af704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_train = model.predict(x_train)\n",
    "P_val = model.predict(x_val)\n",
    "P_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c8d0d9-875a-4acd-9bf5-4a8230baeb23",
   "metadata": {},
   "source": [
    "For example, see the probabilities below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0ea80b-5c9f-4cab-bf36-15063426ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3319465f-a10d-45c0-bc54-4b0debc3e8b9",
   "metadata": {},
   "source": [
    "Thus, we will need to convert the data to our classes of either 0 or 1. If the probability that the data is class 1 is greater than 0.5, we will assign that value to class 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae4ad8b-761a-49ba-a2fc-1cede42cc280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_predictions_df(predictions): \n",
    "    \"\"\"Assign class predicions. Output as pandas dataframe\n",
    "\n",
    "    Parameters \n",
    "    ----------\n",
    "    predictions: 2D np.array \n",
    "        probability predictions from model \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "    \n",
    "    \"\"\"\n",
    "    predict_df = pd.DataFrame(predictions)\n",
    "    predict_df = predict_df.rename(columns = {0: 'prob_0', 1: 'prob_1'})\n",
    "    predict_df['predicted_class'] = np.argmax(predictions, axis=1)\n",
    "    return predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a30cad-ec7d-4a5b-8f7f-11536176a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_train_df = get_class_predictions_df(P_train)\n",
    "P_train_df[\"actual_class\"] = y_train\n",
    "P_train_df[\"set\"] = [\"training\"]*len(P_train_df)\n",
    "\n",
    "P_val_df = get_class_predictions_df(P_val)\n",
    "P_val_df[\"actual_class\"] = y_val\n",
    "P_val_df[\"set\"] = [\"validation\"]*len(P_val_df)\n",
    "\n",
    "P_test_df = get_class_predictions_df(P_test)\n",
    "P_test_df[\"actual_class\"] = y_test\n",
    "P_test_df[\"set\"] = [\"testing\"]*len(P_test_df)\n",
    "\n",
    "col_subset = [\"predicted_class\",\"actual_class\",\"set\"]\n",
    "P_all_df = pd.concat([\n",
    "    P_train_df[col_subset],\n",
    "    P_val_df[col_subset],\n",
    "    P_test_df[col_subset]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facd6b9a-60f4-4584-8631-66f3ef87d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time indices \n",
    "train_idx = list(y_train_df.time.values)\n",
    "val_idx = list(y_val_df.time.values)\n",
    "test_idx = list(y_test_df.time.values)\n",
    "\n",
    "# Add to dataframe \n",
    "P_all_df[\"time\"] = pd.to_datetime(train_idx + val_idx + test_idx)\n",
    "\n",
    "P_all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0302b85c-51c9-4583-8acc-3e68c86e2b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number EPCP per year \n",
    "num_EPCP_by_yr = P_all_df.groupby(P_all_df.time.dt.year)[[\"predicted_class\",\"actual_class\"]].sum()\n",
    "EPCP_by_yr = pd.DataFrame(num_EPCP_by_yr )\n",
    "\n",
    "# Make a plot \n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "pl_pred = EPCP_by_yr.plot(y=\"predicted_class\", ax=ax, marker=\".\", color=\"darkblue\")\n",
    "pl_actual = EPCP_by_yr.plot(y=\"actual_class\", ax=ax, marker=\".\", color=\"magenta\")\n",
    "plt.xlabel(\"year\") \n",
    "plt.ylabel(\"days per year\")\n",
    "#plt.legend().remove()\n",
    "plt.title(\"predicted EPCP occurrences per year in CO\") \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
