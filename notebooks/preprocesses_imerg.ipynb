{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f9d084-d275-43b2-8974-d77a87b26095",
   "metadata": {},
   "source": [
    "# Preprocesses IMERG precip data \n",
    "1) Clip to CO\n",
    "2) Compute average over region \n",
    "3) Assign each timestep to a class -- extreme precip or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5449afb3-f2fc-442b-9606-dbe7ea23ba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr \n",
    "from glob import glob\n",
    "import sys \n",
    "from datetime import datetime\n",
    "import boto3\n",
    "import s3fs\n",
    "\n",
    "# Import helper functions \n",
    "sys.path.insert(0, '../utils')\n",
    "from preprocessing_utils import (\n",
    "    get_state_geom, \n",
    "    convert_lon_360_to_180, \n",
    "    clip_to_geom, \n",
    "    calc_anomalies\n",
    ") \n",
    "import parameters as param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cdb3c5-5237-4fba-af00-f83dcb0120a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get all the filepaths for the specified time range \n",
    "# filepaths_all = []\n",
    "# for year in range(int(param.time_start), int(param.time_end)): \n",
    "#     filepaths_wildcard = \"../data/precip_daily/*3IMERG.{0}*.nc4\".format(year)\n",
    "#     filepaths_all += glob(filepaths_wildcard)\n",
    "# ds = xr.open_mfdataset(filepaths_all).sel(time=param.time_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe66331e-1dbc-4224-ad13-ddf0e2857b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data \n",
    "var = \"precipitation\"\n",
    "filepaths_wildcard = \"../data/precip_daily/*3IMERG*.nc4\"\n",
    "filepaths_all = glob(filepaths_wildcard)\n",
    "ds = xr.open_mfdataset(filepaths_all).sel(time=param.time_period)\n",
    "global_attrs = ds.attrs\n",
    "var_attrs = ds[var].attrs\n",
    "ds = ds[var].to_dataset()\n",
    "\n",
    "# Convert from Julian --> Standard Calendar \n",
    "ds = ds.convert_calendar(\"standard\")\n",
    "\n",
    "# Shift order of dimensions to match reanalysis data \n",
    "ds = ds.transpose(\"time\",\"lat\",\"lon\")\n",
    "\n",
    "# Get Colorado state boundary \n",
    "state = \"Colorado\"\n",
    "geom = get_state_geom(state)\n",
    "\n",
    "# Clip to Colorado geometry \n",
    "ds = clip_to_geom(ds, geom)\n",
    "\n",
    "# Average over entire region\n",
    "ds = ds.mean(dim=[\"lat\",\"lon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302bdcc-8172-49c9-a1bb-71bd8ed2066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into memory \n",
    "ds = ds.compute() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bba67ee-ec94-49f4-aba6-4e80123bdd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 95th percentile precip\n",
    "perc_95 = ds[var].quantile(0.95).item()\n",
    "print(\"95th percentile precip over {0}: {1}\".format(state, perc_95))\n",
    "\n",
    "# Assign classes based on exceedance of 95th percentile \n",
    "extremes_var = \"precip_classes\"\n",
    "ds[extremes_var] = xr.where(ds[var] > perc_95, 1, 0)\n",
    "ds[extremes_var].attrs = {\n",
    "    \"description\":\"95th percentile precipitation\", \n",
    "    \"classes\": \"Class 0: precipitation below threshold \\nClass 1: precipitation exeeds threshold\"\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c68ef9-0927-4fb5-a838-2b14f14829dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the output data \n",
    "output_da = ds[extremes_var]\n",
    "output_ds = output_da.to_dataset()\n",
    "output_ds.attrs = global_attrs\n",
    "output_ds.attrs[\"region\"] = \"Data has been spatially averaged across the state of \"+state\n",
    "output_ds.attrs[\"title\"] = global_attrs[\"title\"] + \" modified to compute extreme precip classes\"\n",
    "output_ds.attrs[\"history\"] = global_attrs[\"history\"] + \"\\nExtreme precip classes produced \" + datetime.today().strftime('%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aa5b05-476f-41ff-aea5-93cfb038a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a gander at the data \n",
    "display(output_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c93b58-9bff-45b7-9b26-d1c11d24108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas DataFrame \n",
    "output_df = output_ds.to_dataframe().reset_index()\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d3365-d102-443e-929a-eb1954aeb670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output to csv \n",
    "filename = \"precip_classes.csv\"\n",
    "output_df.to_csv(\"../data/input_data_preprocessed/{}\".format(filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9628f250-d1e9-4578-bb01-7863f7e9584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Confirm that you're connected to the right S3 bucket\n",
    "# s3 = boto3.resource(service_name='s3')\n",
    "# for bucket in s3.buckets.all():\n",
    "#     # What is printed here should match the variable \"bucket\" below\n",
    "#     print(\"Bucket in S3: \" + bucket.name)\n",
    "\n",
    "# # S3 paths and such \n",
    "# bucket = \"ml-extreme-precip\" # Name of bucket \n",
    "# folder = \"IMERG\" # Name of folder in bucket\n",
    "# s3_path = \"s3://{0}/{1}/\".format(bucket, folder) \n",
    "\n",
    "# # Name to give file \n",
    "# # DO NOT include file extension (this will be .zarr)\n",
    "# filename = output_da.name\n",
    "\n",
    "# # Path to zarr store in AWS bucket\n",
    "# filepath_zarr = \"{}{}.zarr/\".format(s3_path, filename)\n",
    "# print(\"zarr store will be written to path: {}\".format(filepath_zarr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e3f73a-bd58-4a8d-9cab-c07acf8c7ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write zarr to bucket \n",
    "\n",
    "# # Initilize the S3 file system\n",
    "# s3 = s3fs.S3FileSystem()\n",
    "# store = s3fs.S3Map(root=filepath_zarr, s3=s3, check=False)\n",
    "\n",
    "# # Save to zarr\n",
    "# output_ds.to_zarr(\n",
    "#     store=store, \n",
    "#     consolidated=True, \n",
    "#     mode=\"w\" # Overwrite any existing files \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2e3697-2b5b-4c70-bd86-3fe7397247aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now try opening the file from AWS! :D \n",
    "# xr.open_zarr(filepath_zarr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
